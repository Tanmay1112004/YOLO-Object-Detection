{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7c1d3",
   "metadata": {},
   "source": [
    "# ðŸš€ Ultralytics YOLO - Interview Ready Notebook\n",
    "This notebook is designed to help you understand and explain **YOLO (You Only Look Once)** using the **Ultralytics library**. It's structured for:\n",
    "- ðŸ“– Easy revision\n",
    "- ðŸ’¡ Interview explanations\n",
    "- âš¡ Hands-on demos in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bcfb0",
   "metadata": {},
   "source": [
    "## ðŸ”¹ What is YOLO?\n",
    "- **YOLO (You Only Look Once)** is a family of real-time object detection models.\n",
    "- Instead of a sliding window or region proposals, YOLO predicts bounding boxes and class probabilities **in a single forward pass** of the neural network.\n",
    "- YOLO is known for **speed + accuracy** in real-time applications (self-driving cars, surveillance, sports analytics).\n",
    "\n",
    "**Key Idea:** Object detection = classification + localization in one step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4352a6b",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Setup in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04117e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics gradio opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d661b",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Import Libraries and Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f288e6",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Object Detection on Images\n",
    "YOLO can run predictions on **images** easily.\n",
    "- Pretrained models: `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, `yolo11x.pt`\n",
    "- Choose based on speed vs accuracy tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6faf869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "results = model.predict('https://ultralytics.com/images/zidane.jpg')\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd04ca4",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Object Detection on Videos\n",
    "We can run YOLO on video streams (CCTV, dashcams, sports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('https://github.com/ultralytics/assets/releases/download/v0.0.0/bus.jpg')  # replace with video URL/file\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    results = model.predict(frame)\n",
    "    annotated = results[0].plot()\n",
    "    cv2.imshow('YOLO Detection', annotated)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fe65c",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Pose Estimation with YOLO\n",
    "- YOLO also supports **keypoint detection** (pose estimation).\n",
    "- Useful for fitness apps, sports analysis, gesture recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model = YOLO('yolo11n-pose.pt')\n",
    "results = pose_model.predict('https://ultralytics.com/images/bus.jpg')\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2d1dc",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Training YOLO on Custom Data\n",
    "Steps:\n",
    "1. Prepare dataset in **YOLO format** (images + labels in `.txt`).\n",
    "2. Create a `data.yaml` file (with train/val paths + class names).\n",
    "3. Train model:\n",
    "```python\n",
    "model = YOLO('yolo11n.pt')\n",
    "model.train(data='data.yaml', epochs=50, imgsz=640)\n",
    "```\n",
    "4. Evaluate & test the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a9d8f",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Interview Ready Q&A\n",
    "**Q1. Why is YOLO faster than other object detection models?**  \n",
    "ðŸ‘‰ Because it predicts bounding boxes + classes in a **single forward pass** instead of multiple proposals.\n",
    "\n",
    "**Q2. Difference between YOLO and RCNN?**  \n",
    "- RCNN = 2-stage (region proposals + classification)\n",
    "- YOLO = 1-stage (direct detection)\n",
    "\n",
    "**Q3. When would you prefer YOLO over Faster RCNN?**  \n",
    "- YOLO â†’ real-time, resource-limited edge devices.\n",
    "- Faster RCNN â†’ higher accuracy, slower speed.\n",
    "\n",
    "**Q4. Trade-off in YOLO model sizes (n, s, m, l, x)?**  \n",
    "- Small (`n`, `s`) â†’ faster, less accurate.\n",
    "- Large (`l`, `x`) â†’ slower, more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1ca39",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Wrap-up\n",
    "- YOLO = Fast + Accurate real-time detection\n",
    "- Supports **objects + pose + segmentation**\n",
    "- Widely used in industry for real-time AI applications.\n",
    "\n",
    "âœ… With these notes + code, youâ€™re interview ready! ðŸš€"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}