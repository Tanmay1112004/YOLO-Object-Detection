# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ncE6AEjppw8VK8i_OOFBPcCmLwXcQ0Ja
"""

# --- Install dependencies ---
!pip install ultralytics gradio opencv-python-headless

import cv2
import gradio as gr
from ultralytics import YOLO

# Load models (you can change to bigger models like yolo11m.pt or yolo11x.pt if GPU allows)
det_model = YOLO("yolo11n.pt")        # Object detection
pose_model = YOLO("yolo11n-pose.pt")  # Pose estimation for exercise detection

# --------------------------
# IMAGE DETECTION FUNCTION
# --------------------------
def detect_objects(image):
    results = det_model.predict(image)
    return results[0].plot()  # Return image with boxes drawn


# --------------------------
# VIDEO DETECTION FUNCTION
# --------------------------
def detect_video(video, task="object"):
    cap = cv2.VideoCapture(video)
    w, h, fps = (int(cap.get(x)) for x in
                 (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

    out_path = "output.mp4"
    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    model = det_model if task == "object" else pose_model

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        results = model.predict(frame)
        out.write(results[0].plot())

    cap.release()
    out.release()
    return out_path


# --------------------------
# GRADIO FRONTEND
# --------------------------
with gr.Blocks(theme=gr.themes.Soft(primary_hue="indigo")) as demo:
    gr.Markdown(
        "<h1 style='text-align:center;'>ðŸš€ YOLO Object & Video Detection</h1>"
        "<p style='text-align:center;'>Upload an image or video and let YOLO detect everything in real time!</p>"
    )

    with gr.Tab("ðŸ“· Image Detection"):
        image_input = gr.Image(type="numpy", label="Upload Image")
        image_output = gr.Image(type="numpy", label="Detected Image")
        btn1 = gr.Button("Run Detection")
        btn1.click(detect_objects, inputs=image_input, outputs=image_output)

    with gr.Tab("ðŸŽ¥ Video Detection"):
        video_input = gr.Video(label="Upload Video")
        task_choice = gr.Radio(
            ["object", "pose"], value="object", label="Choose Detection Mode"
        )
        video_output = gr.Video(label="Processed Video")
        btn2 = gr.Button("Run Detection on Video")
        btn2.click(detect_video, inputs=[video_input, task_choice], outputs=video_output)

demo.launch()



"""# If you download photo & vedio"""

# --- Install dependencies ---
!pip install ultralytics gradio opencv-python-headless

import cv2
import gradio as gr
from ultralytics import YOLO
import shutil

# Load models
det_model = YOLO("yolo11n.pt")        # Object detection
pose_model = YOLO("yolo11n-pose.pt")  # Pose estimation for exercise detection

# --------------------------
# IMAGE DETECTION FUNCTION
# --------------------------
def detect_objects(image):
    results = det_model.predict(image)
    return results[0].plot()  # Return image with boxes drawn


# --------------------------
# VIDEO DETECTION FUNCTION
# --------------------------
def detect_video(video, task="object"):
    cap = cv2.VideoCapture(video)
    w, h, fps = (int(cap.get(x)) for x in
                 (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

    out_path = "output.mp4"
    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    model = det_model if task == "object" else pose_model

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        results = model.predict(frame)
        out.write(results[0].plot())

    cap.release()
    out.release()

    # Copy file with a user-friendly name for downloading
    download_path = f"processed_{task}_video.mp4"
    shutil.copy(out_path, download_path)

    return download_path, download_path


# --------------------------
# GRADIO FRONTEND
# --------------------------
with gr.Blocks(theme=gr.themes.Soft(primary_hue="indigo")) as demo:
    gr.Markdown(
        "<h1 style='text-align:center;'>ðŸš€ YOLO Object & Video Detection</h1>"
        "<p style='text-align:center;'>Upload an image or video and let YOLO detect everything in real time!</p>"
    )

    with gr.Tab("ðŸ“· Image Detection"):
        image_input = gr.Image(type="numpy", label="Upload Image")
        image_output = gr.Image(type="numpy", label="Detected Image")
        btn1 = gr.Button("Run Detection")
        btn1.click(detect_objects, inputs=image_input, outputs=image_output)

    with gr.Tab("ðŸŽ¥ Video Detection"):
        video_input = gr.Video(label="Upload Video")
        task_choice = gr.Radio(
            ["object", "pose"], value="object", label="Choose Detection Mode"
        )
        video_output = gr.Video(label="Processed Video")
        download_link = gr.File(label="Download Processed Video")
        btn2 = gr.Button("Run Detection on Video")
        btn2.click(
            detect_video,
            inputs=[video_input, task_choice],
            outputs=[video_output, download_link]
        )

demo.launch()



